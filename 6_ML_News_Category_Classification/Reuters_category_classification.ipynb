{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de839864",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# data load and split\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=10000, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d886f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플의 수: 8982\n",
      "테스트 샘플의 수: 2246\n"
     ]
    }
   ],
   "source": [
    "print('훈련 샘플의 수: {}'.format(len(x_train)))\n",
    "print('테스트 샘플의 수: {}'.format(len(x_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4ba227",
   "metadata": {},
   "source": [
    "### 데이터 복원"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55890140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<sos> <unk> <unk> said as a result of its december acquisition of space co it expects earnings per share in 1987 of 1 15 to 1 30 dlrs per share up from 70 cts in 1986 the company said pretax net should rise to nine to 10 mln dlrs from six mln dlrs in 1986 and rental operation revenues to 19 to 22 mln dlrs from 12 5 mln dlrs it said cash flow per share this year should be 2 50 to three dlrs reuter 3\n"
     ]
    }
   ],
   "source": [
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")\n",
    "\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token\n",
    "\n",
    "# 텍스트 복원 확인\n",
    "print(' '.join([index_to_word[index] for index in x_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1d2d1f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n"
     ]
    }
   ],
   "source": [
    "# train data : 텍스트로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_train = decoded\n",
    "print(len(x_train))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbcb847b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2246\n"
     ]
    }
   ],
   "source": [
    "# test data: 텍스트로 변환\n",
    "\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "\n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5c657d",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93bc4e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "# train data : dtm\n",
    "dtmvector = CountVectorizer()\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "\n",
    "# train data : tf-idf\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidfv = tfidf_transformer.fit_transform(x_train_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dff1ed9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data : dtm and tf-idf\n",
    "x_test_dtm = dtmvector.transform(x_test)\n",
    "tfidfv_test = tfidf_transformer.transform(x_test_dtm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b843d852",
   "metadata": {},
   "source": [
    "### model test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99faf9f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chabyeong-gon/anaconda3/envs/ml_clean/lib/python3.10/site-packages/xgboost/sklearn.py:1395: UserWarning: `use_label_encoder` is deprecated in 1.7.0.\n",
      "  warnings.warn(\"`use_label_encoder` is deprecated in 1.7.0.\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "models = {\n",
    "    \"LogisticRegression\": LogisticRegression(\n",
    "        penalty='l2',\n",
    "        max_iter=1000,\n",
    "        random_state=0\n",
    "    ),\n",
    "\n",
    "    \"SVM\": SVC(\n",
    "        kernel='linear',\n",
    "        probability=True,\n",
    "        random_state=0\n",
    "    ),\n",
    "\n",
    "    \"LinearSVC\": LinearSVC(\n",
    "        random_state=0\n",
    "    ),\n",
    "\n",
    "    \"RandomForest\": RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=0,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "\n",
    "    \"ComplementNB\": ComplementNB(),\n",
    "\n",
    "    \"XGBoost\": XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        random_state=0,\n",
    "        eval_metric='logloss',\n",
    "        use_label_encoder=False\n",
    "    ),\n",
    "\n",
    "    \"LightGBM\": LGBMClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.1,\n",
    "        random_state=0\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa9b10a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting 추가\n",
    "\n",
    "models[\"Voting\"] = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lr\", models[\"LogisticRegression\"]),\n",
    "        (\"svm\", models[\"SVM\"]),\n",
    "        (\"cnb\", models[\"ComplementNB\"]),\n",
    "        (\"lgbm\", models[\"LightGBM\"])\n",
    "    ],\n",
    "    voting=\"soft\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "168c7727",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training LogisticRegression\n",
      "Accuracy: 0.7956, F1: 0.4721\n",
      "\n",
      " Training SVM\n",
      "Accuracy: 0.8219, F1: 0.6355\n",
      "\n",
      " Training LinearSVC\n",
      "Accuracy: 0.8299, F1: 0.6808\n",
      "\n",
      " Training RandomForest\n",
      "Accuracy: 0.7600, F1: 0.4445\n",
      "\n",
      " Training ComplementNB\n",
      "Accuracy: 0.7707, F1: 0.4784\n",
      "\n",
      " Training XGBoost\n",
      "Accuracy: 0.8090, F1: 0.6574\n",
      "\n",
      " Training LightGBM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chabyeong-gon/anaconda3/envs/ml_clean/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "/Users/chabyeong-gon/anaconda3/envs/ml_clean/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3998, F1: 0.0244\n",
      "\n",
      " Training Voting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chabyeong-gon/anaconda3/envs/ml_clean/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7155, F1: 0.3180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chabyeong-gon/anaconda3/envs/ml_clean/lib/python3.10/site-packages/sklearn/utils/deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n Training {name}\")\n",
    "    \n",
    "    model.fit(tfidfv, y_train)\n",
    "    y_pred = model.predict(tfidfv_test)\n",
    "    \n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "    \n",
    "    results.append({\n",
    "        \"Vocabulary Size\": 20000,\n",
    "        \"Model\": name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"F1-Score\": f1\n",
    "    })\n",
    "    \n",
    "    print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e21cb0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# voting 개선\n",
    "\n",
    "models[\"Voting_v2\"] = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"lr\", models[\"LogisticRegression\"]),\n",
    "        (\"svm\", models[\"SVM\"]),\n",
    "        (\"cnb\", models[\"ComplementNB\"])\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[2, 2, 1]   # 선형 모델 가중\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f5c5de82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Voting_v2\n",
      "Accuracy: 0.8286, F1: 0.6557\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n Training Voting_v2\")\n",
    "\n",
    "model = models[\"Voting_v2\"]\n",
    "model.fit(tfidfv, y_train)\n",
    "y_pred = model.predict(tfidfv_test)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(f\"Accuracy: {acc:.4f}, F1: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8ea091e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    \"Vocabulary Size\": 20000,\n",
    "    \"Model\": \"Voting_v2\",\n",
    "    \"Accuracy\": acc,\n",
    "    \"F1-Score\": f1\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9402e9",
   "metadata": {},
   "source": [
    "### dense test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad791991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dense layer 준비\n",
    "X_train_dense = tfidfv.toarray()\n",
    "X_test_dense = tfidfv_test.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "902da351",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "n_features = X_train_dense.shape[1]   # 20000\n",
    "n_classes = 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7631e0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model = models.Sequential([\n",
    "    layers.Input(shape=(n_features,)),\n",
    "\n",
    "    layers.Dense(256, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dropout(0.5),\n",
    "\n",
    "    layers.Dense(n_classes, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d93c9441",
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b05a43b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8778 - loss: 0.5107 - val_accuracy: 0.7991 - val_loss: 0.8943\n",
      "Epoch 2/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8884 - loss: 0.4535 - val_accuracy: 0.8036 - val_loss: 0.8927\n",
      "Epoch 3/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8980 - loss: 0.4112 - val_accuracy: 0.8080 - val_loss: 0.8920\n",
      "Epoch 4/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9094 - loss: 0.3666 - val_accuracy: 0.8136 - val_loss: 0.8987\n",
      "Epoch 5/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9182 - loss: 0.3351 - val_accuracy: 0.8130 - val_loss: 0.9079\n",
      "Epoch 6/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9253 - loss: 0.3024 - val_accuracy: 0.8147 - val_loss: 0.9113\n",
      "Epoch 7/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9273 - loss: 0.2768 - val_accuracy: 0.8130 - val_loss: 0.9235\n",
      "Epoch 8/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9331 - loss: 0.2564 - val_accuracy: 0.8164 - val_loss: 0.9333\n",
      "Epoch 9/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9406 - loss: 0.2390 - val_accuracy: 0.8119 - val_loss: 0.9304\n",
      "Epoch 10/10\n",
      "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9434 - loss: 0.2250 - val_accuracy: 0.8152 - val_loss: 0.9601\n"
     ]
    }
   ],
   "source": [
    "history = dense_model.fit(\n",
    "    X_train_dense,\n",
    "    y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=20,\n",
    "    batch_size=256,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ff502969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m71/71\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step\n",
      "0.7992 0.5824\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "y_pred_prob = dense_model.predict(X_test_dense)\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average=\"macro\")\n",
    "\n",
    "print(np.round(acc, 4), np.round(f1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "79e5d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.append({\n",
    "    \"Vocabulary Size\": 20000,\n",
    "    \"Model\": \"Dense\",\n",
    "    \"Accuracy\": acc,\n",
    "    \"F1-Score\": f1\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "853e0f58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Vocabulary Size': 20000,\n",
       "  'Model': 'LogisticRegression',\n",
       "  'Accuracy': 0.7956366874443455,\n",
       "  'F1-Score': 0.4721138497182076},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'SVM',\n",
       "  'Accuracy': 0.8219056099732859,\n",
       "  'F1-Score': 0.6355105649296497},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'LinearSVC',\n",
       "  'Accuracy': 0.8299198575244879,\n",
       "  'F1-Score': 0.6808429075185041},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'RandomForest',\n",
       "  'Accuracy': 0.7600178094390027,\n",
       "  'F1-Score': 0.44449233566244767},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'ComplementNB',\n",
       "  'Accuracy': 0.7707034728406055,\n",
       "  'F1-Score': 0.47835757543524193},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'XGBoost',\n",
       "  'Accuracy': 0.808993766696349,\n",
       "  'F1-Score': 0.6574499256270908},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'LightGBM',\n",
       "  'Accuracy': 0.39982190560997327,\n",
       "  'F1-Score': 0.02439743751125569},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'Voting',\n",
       "  'Accuracy': 0.7154942119323241,\n",
       "  'F1-Score': 0.3180114666330721},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'Voting_v2',\n",
       "  'Accuracy': 0.8285841495992876,\n",
       "  'F1-Score': 0.6556690899684487},\n",
       " {'Vocabulary Size': 20000,\n",
       "  'Model': 'Dense',\n",
       "  'Accuracy': 0.7991985752448798,\n",
       "  'F1-Score': 0.582356929913966}]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab7a8a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml_clean)",
   "language": "python",
   "name": "ml_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
